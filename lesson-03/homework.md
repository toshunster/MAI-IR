# Домашнее задание №3

## Токенизация
Нужно реализовать процесс разбиения текстов документов на токены, который потом будет
использоваться при индексации. Для этого потребуется выработать правила, по которым текст
делится на токены. Необходимо описать их в отчёте, указать достоинства и недостатки
выбранного метода. Привести примеры токенов, которые были выделены неудачно, объяснить,
как можно было бы поправить правила, чтобы исправить найденные проблемы.

В результатах выполнения работы нужно указать следующие статистические данные:

- Количество токенов.
- Среднюю длину токена.

Кроме того, нужно привести время выполнения программы, указать зависимость времени от
объёма входных данных. Указать скорость токенизации в расчёте на килобайт входного текста.
Является ли эта скорость оптимальной? Как её можно ускорить?

## Закон Ципфа
Для своего корпуса необходимо построить график распределения терминов по частотностям в
логарифмической шкале, наложить на этот график закон Ципфа. Объяснить причины
расхождения.

В качестве дополнительного задания, можно (но необязательно) подобрать константы для закона
Мандельброта, наложить полученный график на график распределения терминов по
частотностям. Привести выбранные константы.

## Лемматизация / Стемминг
Добавить в созданную поисковую систему
лемматизацию. В простейшем случае, это просто поиск без учёта словоформ. В более сложном
случае, можно давать бонус большего размера за точное совпадение слов.

Лемматизацию можно
добавлять на этапе индексации, можно на этапе выполнения поискового запроса.
В отчёте должна быть включена оценка качества поиска, после внедрения лемматизации. Стало
ли лучше? Изучите запросы, где качество ухудшилось. Объясните причину ухудшения и как можно
было бы улучшить качество поиска по этим запросам, не ухудшая остальные запросы?
